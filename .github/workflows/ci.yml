name: CI

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]

jobs:
  # ── 1. Lint ─────────────────────────────────────────────────────────────────
  lint:
    name: Lint (ruff)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install ruff
        run: pip install ruff

      - name: Run ruff on core modules
        run: |
          ruff check data_5species/core/ \
            --select E,F,W \
            --ignore E501,W291,W293,E741 \
            --output-format=github

  # ── 2. Validate JSON configs ────────────────────────────────────────────────
  validate-config:
    name: Validate JSON configs
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: data_5species

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Validate prior_bounds.json schema
        run: |
          python - <<'EOF'
          import json, sys

          with open("model_config/prior_bounds.json") as f:
              cfg = json.load(f)

          assert "strategies" in cfg, "missing 'strategies'"
          assert "default_bounds" in cfg, "missing 'default_bounds'"

          required_conditions = [
              "Commensal_Static", "Commensal_HOBIC",
              "Dysbiotic_Static", "Dysbiotic_HOBIC",
          ]
          for cond in required_conditions:
              assert cond in cfg["strategies"], f"missing strategy: {cond}"
              strat = cfg["strategies"][cond]
              assert "locks" in strat, f"{cond}: missing 'locks'"
              assert "bounds" in strat, f"{cond}: missing 'bounds'"
              for idx_str, bnd in strat["bounds"].items():
                  assert len(bnd) == 2, f"{cond}[{idx_str}]: bound must be [lo, hi]"
                  assert bnd[0] <= bnd[1], f"{cond}[{idx_str}]: lo > hi"
                  assert int(idx_str) in range(20), \
                      f"{cond}: param index {idx_str} out of 0-19"

          print("OK — prior_bounds.json is valid")
          EOF

      - name: Validate model_constants.json (if present)
        run: |
          python - <<'EOF'
          import json, os
          path = "model_config/model_constants.json"
          if not os.path.exists(path):
              print("SKIP — model_constants.json not found")
          else:
              with open(path) as f:
                  json.load(f)
              print("OK — model_constants.json is valid JSON")
          EOF

  # ── 3. Unit tests (matrix: py3.10 + py3.11) ─────────────────────────────────
  unit-test:
    name: Unit tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10", "3.11"]
    defaults:
      run:
        working-directory: data_5species

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: pip install --upgrade pip && pip install numpy scipy pandas

      - name: Syntax check — all core modules
        run: |
          python -m py_compile core/nishioka_model.py
          python -m py_compile core/tmcmc.py
          python -m py_compile core/evaluator.py
          python -m py_compile core/mcmc.py
          echo "OK — syntax check passed"

      - name: Test — nishioka_model structure
        run: |
          python - <<'EOF'
          import sys
          sys.path.insert(0, ".")
          from core.nishioka_model import (
              INTERACTION_GRAPH_JSON, get_nishioka_mask,
              get_nishioka_bounds, get_condition_bounds,
          )
          import numpy as np

          g = INTERACTION_GRAPH_JSON
          assert len(g["nodes"]) == 5, f"expected 5 nodes, got {len(g['nodes'])}"
          assert len(g["active_edges"]) == 5
          assert len(g["locked_edges"]) == 5

          mask = get_nishioka_mask()
          assert mask.shape == (5, 5), f"bad shape: {mask.shape}"
          assert mask.sum() == 15, f"expected 15 active, got {mask.sum()}"

          for cond, cult in [("Commensal", "Static"), ("Commensal", "HOBIC"),
                              ("Dysbiotic", "Static"), ("Dysbiotic", "HOBIC")]:
              bounds = get_condition_bounds(cond, cult)
              assert len(bounds) > 0, f"empty bounds for {cond} {cult}"

          print("OK — nishioka_model tests passed")
          EOF

      - name: Test — build_likelihood_weights
        run: |
          python - <<'EOF'
          import sys
          sys.path.insert(0, ".")
          import numpy as np
          from core.evaluator import build_likelihood_weights

          W = build_likelihood_weights(n_obs=5, n_species=5)
          assert W.shape == (5, 5), f"bad shape: {W.shape}"

          # Pg column (idx=4) upweighted by lambda_pg=5.0
          assert np.all(W[:, 4] == 5.0), "Pg column should be 5.0"

          # Early non-Pg rows == 1.0
          assert np.all(W[:3, :4] == 1.0), "early non-Pg should be 1.0"

          # Last n_late=2 rows upweighted by lambda_late=3.0
          assert W[3, 0] == 3.0 and W[4, 0] == 3.0, "late non-Pg should be 3.0"
          assert W[3, 4] == 15.0 and W[4, 4] == 15.0, "late Pg should be 5*3=15.0"

          # Custom weights, no late
          W2 = build_likelihood_weights(5, 5, lambda_pg=2.0, lambda_late=1.0, n_late=0)
          assert np.all(W2[:, 4] == 2.0)
          assert np.all(W2[:, :4] == 1.0)

          print("OK — build_likelihood_weights tests passed")
          EOF

      - name: Test — reflect_into_bounds
        run: |
          python - <<'EOF'
          import sys
          sys.path.insert(0, ".")
          from core.tmcmc import reflect_into_bounds

          eps = 1e-10

          # Inside bounds → unchanged
          assert abs(reflect_into_bounds(0.5, 0.0, 1.0) - 0.5) < eps

          # At bounds → unchanged
          assert abs(reflect_into_bounds(0.0, 0.0, 1.0) - 0.0) < eps
          assert abs(reflect_into_bounds(1.0, 0.0, 1.0) - 1.0) < eps

          # Above upper → reflected back
          v = reflect_into_bounds(1.1, 0.0, 1.0)
          assert abs(v - 0.9) < eps, f"reflect 1.1 → expected 0.9, got {v}"

          # Below lower → reflected
          v = reflect_into_bounds(-0.1, 0.0, 1.0)
          assert abs(v - 0.1) < eps, f"reflect -0.1 → expected 0.1, got {v}"

          # Far outside → still in bounds
          v = reflect_into_bounds(3.7, 0.0, 1.0)
          assert 0.0 <= v <= 1.0, f"far outside: {v} not in [0,1]"

          print("OK — reflect_into_bounds tests passed")
          EOF

      - name: Test — log_likelihood_sparse (finite + sign)
        run: |
          python - <<'EOF'
          import sys
          sys.path.insert(0, ".")
          import numpy as np
          from core.evaluator import log_likelihood_sparse

          n_obs, n_sp = 5, 5
          rng = np.random.default_rng(42)

          mu   = rng.uniform(0.1, 0.9, (n_obs, n_sp))
          sig  = np.ones((n_obs, n_sp)) * 0.01
          data = rng.uniform(0.1, 0.9, (n_obs, n_sp))

          ll = log_likelihood_sparse(mu, sig, data, sigma_obs=0.05)
          assert np.isfinite(ll), f"log-likelihood is not finite: {ll}"
          assert ll <= 0.0, f"log-likelihood should be <= 0, got {ll}"

          # Perfect fit → higher likelihood
          ll_perfect = log_likelihood_sparse(mu, sig, mu, sigma_obs=0.05)
          assert ll_perfect >= ll, "perfect fit should have higher ll"

          # With weights
          W = np.ones((n_obs, n_sp))
          W[:, 4] *= 5.0
          ll_w = log_likelihood_sparse(mu, sig, data, sigma_obs=0.05, weights=W)
          assert np.isfinite(ll_w)

          print(f"OK — log_likelihood_sparse: ll={ll:.3f}, perfect={ll_perfect:.3f}")
          EOF
